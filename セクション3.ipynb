{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本セクションの目次\n",
    "1. Avroフォーマット\n",
    "2. 前方互換と後方互換と完全互換\n",
    "3. メッセージキューとAvroを連携してみよう\n",
    "4. Avroファイルの読み書き\n",
    "5. Avroで前方互換をやってみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コンソールで設定したSparkとNoteBookを接続します(動かす前に毎度実行する必要があります)\n",
    "import findspark\n",
    "findspark.init(\"/home/pyspark/spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: hive.exec.dynamic.partition.mode\n",
      "Warning: Ignoring non-Spark config property: hive.exec.dynamic.partition\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/pyspark/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/pyspark/spark-3.2.0-bin-hadoop3.2/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/pyspark/.ivy2/cache\n",
      "The jars for the packages stored in: /home/pyspark/.ivy2/jars\n",
      "org.apache.spark#spark-streaming_2.13 added as a dependency\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "org.apache.spark#spark-avro_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a28822ed-5037-4a99-814c-64304dc0d58b;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.2.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.2.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.8.0 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.1 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.1 in central\n",
      "\tfound org.apache.htrace#htrace-core4;4.1.0-incubating in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.2.0 in central\n",
      "\tfound org.tukaani#xz;1.8 in central\n",
      ":: resolution report :: resolve 640ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.1 from central in [default]\n",
      "\torg.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.8.0 from central in [default]\n",
      "\torg.apache.spark#spark-avro_2.12;3.2.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.2.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.2.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.tukaani#xz;1.8 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   15  |   0   |   0   |   0   ||   15  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a28822ed-5037-4a99-814c-64304dc0d58b\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 15 already retrieved (0kB/8ms)\n",
      "22/01/05 06:34:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "#pysparkに必要なライブラリを読み込む\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#spark sessionの作成\n",
    "# spark.ui.enabled trueとするとSparkのGUI画面を確認することができます\n",
    "# spark.eventLog.enabled true　とすると　GUIで実行ログを確認することができます\n",
    "# GUIなどの確認は最後のセクションで説明を行います。\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"chapter1\") \\\n",
    "    .config(\"hive.exec.dynamic.partition\", \"true\") \\\n",
    "    .config(\"hive.exec.dynamic.partition.mode\", \"nonstrict\") \\\n",
    "    .config(\"spark.sql.session.timeZone\", \"JST\") \\\n",
    "    .config(\"spark.ui.enabled\",\"true\") \\\n",
    "    .config(\"spark.eventLog.enabled\",\"true\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-streaming_2.13:3.2.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0,org.apache.spark:spark-avro_2.12:3.2.0\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# パッケージを複数渡したい時は「,」で繋いで渡します。\n",
    "# Sparkのバージョンにしっかりと合わせます(今回はSparkのバージョンが3.2を使っています。)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ビッグデータの世界のDDL\n",
    "\n",
    "ビッグデータの世界でのDDLはRDSと同じ様にDDL文を実行することが可能です。  \n",
    "今回は以下のDDLについてみていきましょう  \n",
    "\n",
    "- Create Database 文\n",
    "- CREATE EXTERNAL TABLE文\n",
    "- CREATE VIEW\n",
    "- ADD PARTITION(MSCK REPAIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE DATABASE文\n",
    "データベースの作成を行います。\n",
    "こちらはRDSなどのCreate Database　と同じ方法で作成が可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/05 06:34:53 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "22/01/05 06:34:53 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "Wed Jan 05 06:34:54 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 06:34:54 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 06:34:54 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 06:34:54 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 06:34:54 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 06:34:54 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 06:34:54 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 06:34:54 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "22/01/05 06:34:55 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "22/01/05 06:34:55 WARN ObjectStore: Failed to get database super_crush_course, returning NoSuchObjectException\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create database if not exists super_crush_course\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|namespace                   |\n",
      "+----------------------------+\n",
      "|data_management_crush_course|\n",
      "|default                     |\n",
      "|metadata_tmp                |\n",
      "|super_crush_course          |\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# データベースの一覧を見てみましょう\n",
    "spark.sql(\"show databases\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE EXTERNAL TABLE文\n",
    "テーブル定義の構成要素をみていきましょう\n",
    "\n",
    "```\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS super_crush_course.csv_table ( id INT, date STRING)\n",
    "PARTITIONED BY (dt INT)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LOCATION '/home/pyspark/super_crush_course.db/csv_table/dataset/parquet/';\n",
    "\n",
    "#S3などであれば、以下のように設定を変えることも可能です。\n",
    "LOCATION 's3://data.platform/super_crush_course.db/raw_zone/sampletable/';\n",
    "\n",
    "```\n",
    "\n",
    "ビッグデータの世界では、実データとデータベース定義/テーブル定義(メタデータ)は明確に分離されています。  \n",
    "今回のコースだと実データはローカル端末のSSD(HDD)でテーブル定義はMysqlに登録されています。  \n",
    "明確に分離されているからこそ、場所を指し示す宣言であるLocationが必要になってきます  \n",
    "\n",
    "ロケーションは「super_crush_course.db」とDB名.db/TABLE名とすることが通例です。  \n",
    "Externalは外部のという意味で、オンプレ環境の場合はつけないことが多かったが、クラウド環境ではつけるのが必須となっている設定。\n",
    "\n",
    "メタデータについてさらに詳しく知りたい方は、以下の記事を参照してみてください  \n",
    "「【PythonとSparkで始めるデータマネジメント入門】 ビッグデータレイクのための統合メタデータ管理入門」\n",
    "\n",
    "上記の例は、CSV形式のテーブルです。  \n",
    "それ以外にもParquet形式、Avro形式でテーブルを作成することができます。\n",
    "\n",
    "```\n",
    "# パーティションつきのテーブル\n",
    "CREATE TABLE IF NOT EXISTS super_crush_course.parquet_table \n",
    "(code String, gengo String,wareki String,seireki String,chu String,sokei String,jinko_male String,jinko_femail String)\n",
    "PARTITIONED BY (kenmei String)\n",
    "STORED AS PARQUET\n",
    "TBLPROPERTIES (\"parquet.compression\"=\"SNAPPY\");\n",
    "LOCATION '/home/pyspark/super_crush_course.db/parquet_table';\n",
    "\n",
    "```\n",
    "\n",
    "圧縮形式と保存するファイルフォーマットを指定してテーブルの作成を行なっていきます。  \n",
    "ちなみにテーブル定義のカラムは、今回読み込んだCSV/JSONのスキーマになります。  \n",
    "Partitionとはデータの区切りのことで、kenmeiを区切りとしてデータを保存しています(次のレクチャーにて)。　 \n",
    "\n",
    "```\n",
    "# パーティションなしのテーブルの場合\n",
    "CREATE TABLE IF NOT EXISTS super_crush_course.parquet_table_with_no_partition\n",
    "(code String, gengo String,kenmei, Stringwareki String,seireki String,chu String,sokei String,jinko_male String,jinko_femail String)\n",
    "STORED AS PARQUET\n",
    "TBLPROPERTIES ('parquet.compression'='SNAPPY')\n",
    "LOCATION '/home/pyspark/super_crush_course.db/parquet_table_with_no_partition'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## テーブル作成\n",
    "# テーブル作成も同様に、spark.sqlを使ってテーブルを作成していきます。\n",
    "# ロケーションはセクション2で出力したディレクトリになります。\n",
    "\n",
    "# Parquetテーブルの作成(パーティションあり)\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS super_crush_course.parquet_table_with_partition \n",
    "(code String, gengo String,wareki String,seireki String,chu String,sokei String,jinko_male String,jinko_femail String)\n",
    "PARTITIONED BY (kenmei String)\n",
    "STORED AS PARQUET\n",
    "TBLPROPERTIES ('parquet.compression'='SNAPPY')\n",
    "LOCATION '/home/pyspark/super_crush_course.db/parquet_table_with_partition'\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# Paruqetテーブルの作成(パーティションなし)\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS super_crush_course.parquet_table_with_no_partition \n",
    "(code String, gengo String,wareki String,kenmei String,seireki String,chu String,sokei String,jinko_male String,jinko_femail String)\n",
    "STORED AS PARQUET\n",
    "TBLPROPERTIES ('parquet.compression'='SNAPPY')\n",
    "LOCATION '/home/pyspark/super_crush_course.db/parquet_table_with_no_partition'\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AVROテーブルの作成(パーティションあり)\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS super_crush_course.avro_table_with_partition \n",
    "(code String, gengo String,wareki String,seireki String,chu String,sokei String,jinko_male String,jinko_femail String)\n",
    "PARTITIONED BY (kenmei String)\n",
    "STORED AS AVRO\n",
    "TBLPROPERTIES ('parquet.compression'='SNAPPY')\n",
    "LOCATION '/home/pyspark/super_crush_course.db/parquet_table_with_partition'\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# AVROテーブルの作成(パーティションなし)\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS super_crush_course.avro_table_with_no_partition \n",
    "(code String, gengo String,wareki String,kenmei String,seireki String,chu String,sokei String,jinko_male String,jinko_femail String)\n",
    "STORED AS AVRO\n",
    "TBLPROPERTIES ('parquet.compression'='SNAPPY')\n",
    "LOCATION '/home/pyspark/super_crush_course.db/avro_table_with_no_partition'\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------------------+-----------+\n",
      "|namespace         |tableName                      |isTemporary|\n",
      "+------------------+-------------------------------+-----------+\n",
      "|super_crush_course|avro_table_with_no_partition   |false      |\n",
      "|super_crush_course|avro_table_with_partition      |false      |\n",
      "|super_crush_course|parquet_table_with_no_partition|false      |\n",
      "|super_crush_course|parquet_table_with_partition   |false      |\n",
      "+------------------+-------------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 作成したテーブルを見てみましょう\n",
    "spark.sql(\"show tables in super_crush_course\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD PRTITION\n",
    "パーティションを認識するためにコマンドを発行する必要があります。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|partition|\n",
      "+---------+\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# パーティションも管理されている\n",
    "spark.sql(\"show partitions super_crush_course.parquet_table_with_partition\").show(n=2)\n",
    "# 本来件名があってほしいが。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+-----+------+------+-------+-------+------+----------+------------+\n",
      "|                               code|gengo|wareki|kenmei|seireki|    chu| sokei|jinko_male|jinko_femail|\n",
      "+-----------------------------------+-----+------+------+-------+-------+------+----------+------------+\n",
      "|2)　長野県西筑摩群山口村と岐阜県...| null|  null|  null|   null|   null|  null|      null|        null|\n",
      "|                                 38| 昭和|    60|  1985|   null|1529983|728506|      null|      愛媛県|\n",
      "+-----------------------------------+-----+------+------+-------+-------+------+----------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# パーティションがテーブルは。。？クエリしてみる\n",
    "spark.sql(\"select * from super_crush_course.parquet_table_with_no_partition\").show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+-------+---+-----+----------+------------+------+\n",
      "|code|gengo|wareki|seireki|chu|sokei|jinko_male|jinko_femail|kenmei|\n",
      "+----+-----+------+-------+---+-----+----------+------------+------+\n",
      "+----+-----+------+-------+---+-----+----------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# パーティションがあってadd paritionをしていないテーブルは。。？クエリしてみる\n",
    "spark.sql(\"select * from super_crush_course.parquet_table_with_partition\").show(n=2)\n",
    "# データを見ることができない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# パーティションを追加してみる\n",
    "# パーティションの追加には２種類存在しています\n",
    "# add partition\n",
    "# msck repair table名\n",
    "spark.sql(\"alter table super_crush_course.parquet_table_with_partition add if not exists  partition (kenmei='東京都')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|                    partition|\n",
      "+-----------------------------+\n",
      "|         kenmei=__HIVE_DEF...|\n",
      "|                kenmei=三重県|\n",
      "|                kenmei=京都府|\n",
      "|          kenmei=人口集中地区|\n",
      "|kenmei=人口集中地区以外の地区|\n",
      "|                kenmei=佐賀県|\n",
      "|                  kenmei=全国|\n",
      "|                kenmei=兵庫県|\n",
      "|                kenmei=北海道|\n",
      "|                kenmei=千葉県|\n",
      "|              kenmei=和歌山県|\n",
      "|                kenmei=埼玉県|\n",
      "|                kenmei=大分県|\n",
      "|                kenmei=大阪府|\n",
      "|                kenmei=奈良県|\n",
      "|                kenmei=宮城県|\n",
      "|                kenmei=宮崎県|\n",
      "|                kenmei=富山県|\n",
      "|                kenmei=山口県|\n",
      "|                kenmei=山形県|\n",
      "+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# パーティションも管理されている\n",
    "spark.sql(\"show partitions super_crush_course.parquet_table_with_partition\").show(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+-----+------+-------+----+-------+----------+------------+------+\n",
      "|                               code|gengo|wareki|seireki| chu|  sokei|jinko_male|jinko_femail|kenmei|\n",
      "+-----------------------------------+-----+------+-------+----+-------+----------+------------+------+\n",
      "|2)　長野県西筑摩群山口村と岐阜県...| null|  null|   null|null|   null|      null|        null|  null|\n",
      "|                                 38| 昭和|    60|   1985|null|1529983|    728506|        null|愛媛県|\n",
      "|                                 38| 昭和|    25|   1950|null|1521878|    742092|        null|愛媛県|\n",
      "|                                 38| 平成|     2|   1990|null|1515025|    716940|        null|愛媛県|\n",
      "|                                 38| 昭和|    30|   1955|null|1540628|    749342|        null|愛媛県|\n",
      "|                                 38| 昭和|    55|   1980|null|1506637|    718517|        null|愛媛県|\n",
      "|                                 38| 昭和|    40|   1965|null|1446384|    688063|        null|愛媛県|\n",
      "|                                 38| 昭和|    45|   1970|null|1418124|    670980|        null|愛媛県|\n",
      "|                                 38| 昭和|    35|   1960|  2)|1500687|    721311|        null|愛媛県|\n",
      "|                                 38| 大正|    14|   1925|null|1096366|    542271|        null|愛媛県|\n",
      "|                                 38| 昭和|    20|   1945|  1)|1361484|    635305|        null|愛媛県|\n",
      "|                                 38| 昭和|    15|   1940|null|1178705|    580839|        null|愛媛県|\n",
      "|                                 38| 平成|    17|   2005|null|1467815|    691677|        null|愛媛県|\n",
      "|                                 38| 平成|    22|   2010|null|1431493|    673326|        null|愛媛県|\n",
      "|                                 38| 昭和|    50|   1975|null|1465215|    697794|        null|愛媛県|\n",
      "|                                 38| 昭和|     5|   1930|null|1142122|    564699|        null|愛媛県|\n",
      "|                                 38| 昭和|    10|   1935|null|1164898|    575627|        null|愛媛県|\n",
      "|                                 38| 平成|    27|   2015|null|1385262|    654380|        null|愛媛県|\n",
      "|                                 01| 平成|    27|   2015|null|5381733|   2537089|        null|北海道|\n",
      "|                                 01| 昭和|    15|   1940|null|3272718|   1695600|        null|北海道|\n",
      "+-----------------------------------+-----+------+-------+----+-------+----------+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 再度検索を行ってみる\n",
    "# パーティションがあってadd paritionをしていないテーブルは。。？クエリしてみる\n",
    "spark.sql(\"select * from super_crush_course.parquet_table_with_partition\").show()\n",
    "# 追加した東京都のデータだけ見える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一個づつAdd partitionするのは面倒なのでmsckを使う(ただし時間がかかる場合が多いので、日々の処理であればadd partitionを選択する方がいい)\n",
    "spark.sql(\"msck repair table super_crush_course.parquet_table_with_partition\")\n",
    "spark.sql(\"msck repair table super_crush_course.avro_table_with_partition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create View\n",
    "ビューを作成します。\n",
    "ビューとは、仮想的なテーブルのことでデータを生成しなくてもテーブルを生成することが可能です。\n",
    "\n",
    "言葉で伝えるより実際に見た方がいいと思うので、早速作ってみましょう。　　\n",
    "\n",
    "手っ取り早くクエリを簡単にしたい場合に有効です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create view\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "create view parquet_view (gengo)\n",
    "as \n",
    "select gengo from \n",
    "super_crush_course.parquet_table_with_partition\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|gengo|\n",
      "+-----+\n",
      "| null|\n",
      "| 昭和|\n",
      "| 昭和|\n",
      "| 平成|\n",
      "| 昭和|\n",
      "| 昭和|\n",
      "| 昭和|\n",
      "| 昭和|\n",
      "| 昭和|\n",
      "| 大正|\n",
      "| 昭和|\n",
      "| 昭和|\n",
      "| 平成|\n",
      "| 平成|\n",
      "| 昭和|\n",
      "| 昭和|\n",
      "| 昭和|\n",
      "| 平成|\n",
      "| 平成|\n",
      "| 昭和|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from parquet_view\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テンポラリテーブル\n",
    "テンポラリーテーブルとはデータフレームから一時的にテーブルを作成することで、SparkSessionごとに生成が可能です。\n",
    "\n",
    "特にスキーマオンリードで読み込んだdataframeを一時的にテーブルにすることで、SQLでの操作を可能にすることができます。\n",
    "\n",
    "一連の流れを見てみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テンポラリーテーブルの作成\n",
    "json_df=spark.read.json(\"./dataset/jinko.json\")\n",
    "json_df.createOrReplaceTempView(\"json_tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+------------+----------+------+-------+--------+------+\n",
      "| chu|code|gengo|jinko_female|jinko_male|kenmei|seireki|   sokei|wareki|\n",
      "+----+----+-----+------------+----------+------+-------+--------+------+\n",
      "|null|  13| 大正|     1746439|   1952989|東京都|   1920| 3699428|     9|\n",
      "|null|  13| 大正|     2097535|   2387609|東京都|   1925| 4485144|    14|\n",
      "|null|  13| 昭和|     2553355|   2855323|東京都|   1930| 5408678|     5|\n",
      "|null|  13| 昭和|     3044223|   3325696|東京都|   1935| 6369919|    10|\n",
      "|null|  13| 昭和|     3559096|   3795875|東京都|   1940| 7354971|    15|\n",
      "|  1)|  13| 昭和|     1700139|   1788145|東京都|   1945| 3488284|    20|\n",
      "|null|  13| 昭和|     3108111|   3169389|東京都|   1950| 6277500|    25|\n",
      "|null|  13| 昭和|     3921261|   4115823|東京都|   1955| 8037084|    30|\n",
      "|  2)|  13| 昭和|     4686779|   4997023|東京都|   1960| 9683802|    35|\n",
      "|null|  13| 昭和|     5304661|   5564583|東京都|   1965|10869244|    40|\n",
      "|null|  13| 昭和|     5607062|   5801009|東京都|   1970|11408071|    45|\n",
      "|null|  13| 昭和|     5760181|   5913373|東京都|   1975|11673554|    50|\n",
      "|null|  13| 昭和|     5762001|   5856280|東京都|   1980|11618281|    55|\n",
      "|null|  13| 昭和|     5874334|   5955029|東京都|   1985|11829363|    60|\n",
      "|null|  13| 平成|     5885790|   5969773|東京都|   1990|11855563|     2|\n",
      "|null|  13| 平成|     5880901|   5892704|東京都|   1995|11773605|     7|\n",
      "|null|  13| 平成|     6035539|   6028562|東京都|   2000|12064101|    12|\n",
      "|null|  13| 平成|     6311706|   6264895|東京都|   2005|12576601|    17|\n",
      "|null|  13| 平成|     6647278|   6512110|東京都|   2010|13159388|    22|\n",
      "|null|  13| 平成|     6848581|   6666690|東京都|   2015|13515271|    27|\n",
      "+----+----+-----+------------+----------+------+-------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#　json_tempの検索\n",
    "spark.sql(\"select * from json_tmp where kenmei='東京都'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ビッグデータ世界のDMLとは\n",
    "\n",
    "ビッグデータの世界のSQLは基本的にSQL’ライク’です。  \n",
    "というのもRDSのSQLを前提にしてライクと言っているだけなので、ビッグデータ世界を中心としたらSQLそのものです。  \n",
    "RDSでのSQLに慣れている人は、ビッグデータの世界のSQLは難なくこなすことができると思います。  \n",
    "\n",
    "- SELECT\n",
    "- CTAS\n",
    "- SELECT INSERT\n",
    "- INSERT?\n",
    "- UPDATE?\n",
    "- DELETE?\n",
    "\n",
    "今回は4つのDMLを確認してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+----------------------+-------+----+--------+----------+------------+\n",
      "|code|gengo|wareki|                kenmei|seireki| chu|   sokei|jinko_male|jinko_femail|\n",
      "+----+-----+------+----------------------+-------+----+--------+----------+------------+\n",
      "|  25| 平成|    22|                滋賀県|   2010|null| 1410777|    696769|        null|\n",
      "|  27| 昭和|    10|                大阪府|   1935|null| 4297174|   2241666|        null|\n",
      "|  28| 昭和|    45|                兵庫県|   1970|null| 4667928|   2299961|        null|\n",
      "|  32| 平成|     7|                島根県|   1995|null|  771441|    368789|        null|\n",
      "|  27| 昭和|    60|                大阪府|   1985|null| 8668095|   4286445|        null|\n",
      "|  38| 昭和|    60|                愛媛県|   1985|null| 1529983|    728506|        null|\n",
      "|  13| 昭和|    50|                東京都|   1975|null|11673554|   5913373|        null|\n",
      "|  12| 昭和|    35|                千葉県|   1960|  2)| 2306010|   1128734|        null|\n",
      "|  10| 昭和|    50|                群馬県|   1975|null| 1756480|    859364|        null|\n",
      "|  21| 昭和|    25|                岐阜県|   1950|null| 1544538|    762295|        null|\n",
      "|  43| 昭和|    45|                熊本県|   1970|null| 1700229|    798152|        null|\n",
      "|  36| 昭和|    20|                徳島県|   1945|  1)|  835763|    386052|        null|\n",
      "|  22| 昭和|    50|                静岡県|   1975|null| 3308799|   1627797|        null|\n",
      "|  38| 昭和|    25|                愛媛県|   1950|null| 1521878|    742092|        null|\n",
      "|  44| 昭和|    45|                大分県|   1970|null| 1155566|    540541|        null|\n",
      "|  10| 昭和|    40|                群馬県|   1965|null| 1605584|    778916|        null|\n",
      "|  21| 昭和|    60|                岐阜県|   1985|null| 2028536|    986919|        null|\n",
      "|  20| 昭和|    30|                長野県|   1955|null| 2021292|    979004|        null|\n",
      "|  35| 平成|    22|                山口県|   2010|null| 1451338|    684176|        null|\n",
      "|  0B| 平成|     7|人口集中地区以外の地区|   1995|null|44315576|  21546996|        null|\n",
      "+----+-----+------+----------------------+-------+----+--------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----+-----+------+-------+----+--------+----------+------------+------+\n",
      "|code|gengo|wareki|seireki| chu|   sokei|jinko_male|jinko_femail|kenmei|\n",
      "+----+-----+------+-------+----+--------+----------+------------+------+\n",
      "|  13| 平成|    17|   2005|null|12576601|   6264895|        null|東京都|\n",
      "|  13| 昭和|    55|   1980|null|11618281|   5856280|        null|東京都|\n",
      "|  13| 平成|     7|   1995|null|11773605|   5892704|        null|東京都|\n",
      "|  13| 昭和|    25|   1950|null| 6277500|   3169389|        null|東京都|\n",
      "|  13| 大正|     9|   1920|null| 3699428|   1952989|        null|東京都|\n",
      "|  13| 昭和|     5|   1930|null| 5408678|   2855323|        null|東京都|\n",
      "|  13| 平成|    27|   2015|null|13515271|   6666690|        null|東京都|\n",
      "|  13| 平成|     2|   1990|null|11855563|   5969773|        null|東京都|\n",
      "|  13| 平成|    22|   2010|null|13159388|   6512110|        null|東京都|\n",
      "|  13| 昭和|    60|   1985|null|11829363|   5955029|        null|東京都|\n",
      "|  13| 大正|    14|   1925|null| 4485144|   2387609|        null|東京都|\n",
      "|  13| 昭和|    30|   1955|null| 8037084|   4115823|        null|東京都|\n",
      "|  13| 昭和|    50|   1975|null|11673554|   5913373|        null|東京都|\n",
      "|  13| 平成|    12|   2000|null|12064101|   6028562|        null|東京都|\n",
      "|  13| 昭和|    35|   1960|  2)| 9683802|   4997023|        null|東京都|\n",
      "|  13| 昭和|    15|   1940|null| 7354971|   3795875|        null|東京都|\n",
      "|  13| 昭和|    20|   1945|  1)| 3488284|   1788145|        null|東京都|\n",
      "|  13| 昭和|    10|   1935|null| 6369919|   3325696|        null|東京都|\n",
      "|  13| 昭和|    40|   1965|null|10869244|   5564583|        null|東京都|\n",
      "|  13| 昭和|    45|   1970|null|11408071|   5801009|        null|東京都|\n",
      "+----+-----+------+-------+----+--------+----------+------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wed Jan 05 08:23:16 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 08:23:16 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 08:33:37 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 08:33:37 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 09:23:16 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 09:23:16 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 09:33:37 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 09:33:37 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 10:23:16 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 10:23:16 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 10:33:37 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 10:33:37 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 11:23:17 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 11:23:17 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 11:33:37 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 11:33:37 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 12:23:17 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 12:23:17 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 12:33:37 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 12:33:37 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 13:23:17 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 13:23:17 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 13:33:37 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Wed Jan 05 13:33:37 UTC 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n"
     ]
    }
   ],
   "source": [
    "# SELECT\n",
    "spark.sql(\"select * from super_crush_course.parquet_table_with_no_partition\").show()\n",
    "\n",
    "## パーティションつきのテーブルを検索してみる\n",
    "spark.sql(\"select * from super_crush_course.parquet_table_with_partition where kenmei ='東京都'\").show()\n",
    "\n",
    "# パーティションなしの場合は、すべてのデータを走査してから絞り込みます\n",
    "# パーティションありの場合は、特定のパーティション配下のディレクトリのみをチェックします\n",
    "\n",
    "# 大体のRDSのSQLでできることは実行可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTAS\n",
    "Create Table As Selectの略です。\n",
    "\n",
    "簡単にいうと、Selectの返却結果からテーブルを作成することが可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTASの実演"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECT INSERT\n",
    "SELECT INSERTの場合は、ADD PARTITIONは不要です"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT INSERTの実演"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSERT/UPDATE/DELETE?\n",
    "ビッグデータの世界では原則としてACIDをサポートしていません。  \n",
    "そのため、UPDATEやDELETがサポートされていないことが多いです。\n",
    "\n",
    "INSERTは単体で利用することはできますが、あまり出番がなく前述で紹介したSELECT INSERTでの出番が大半です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分析関数の練習をしよう\n",
    "ここからは、分析関数の練習をしてみましょう。  \n",
    "\n",
    "- agg\n",
    "- window(over)\n",
    "- ピボットテーブル\n",
    "- lag関数\n",
    "\n",
    "データフレームでの操作とSQLでの操作を対比させながら実行していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ピボットテーブル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAG関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データフレーム限定 RDDによる一行づつの操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "578f5f657c2fb65ecadb997ad60e5cf2da380ecec34305a6dd913dc5b96e257c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('3.9.1': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
